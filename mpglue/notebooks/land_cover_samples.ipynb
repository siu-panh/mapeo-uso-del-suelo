{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0B3B2E;float:right;font-family:Calibri\">Jordan Graesser</span>\n",
    "\n",
    "# MpGlue\n",
    "### Land cover samples\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook we will learn to load and visualize land cover samples\n",
    "* MpGlue has a `classification` interface that provides modules for handling land cover samples, training classification and regression models, and predicting land cover on satellite imagery.\n",
    "* Let's start with setting up the `classification` class and loading land cover data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_centroid_histogram', '_create_indices', '_default_parameters', '_get_feas', '_get_slope', '_index_samples', '_load_model', '_mask_background', '_num_rows_cols', '_plot_colors', '_predict', '_recode_labels', '_remove_classes', '_remove_min_observations', '_remove_outliers', '_scale_p_vars', '_set_model', '_set_parameters', '_stack_samples', '_stratify', '_train_model', '_transform4crf', '_update_class_counts', 'add_variable_names', 'compare_features', 'compare_samples', 'construct_model', 'copy', 'extract_endmembers', 'get_abundance', 'get_class_subsample', 'get_test_train', 'grid_search', 'load4crf', 'model_options', 'optimize_parameters', 'predict', 'predict_array', 'rank_feas', 'recursive_elimination', 'remove_outliers', 'remove_values', 'semi_supervised', 'split_samples', 'stack_majority', 'sub_feas', 'test_accuracy', 'time_stamp', 'vis_data', 'vis_decision', 'vis_dimensionality_reduction', 'vis_k_means', 'vis_parallel_coordinates', 'vis_series', 'weight_samples']\n"
     ]
    }
   ],
   "source": [
    "import mpglue as gl\n",
    "\n",
    "# Let's set the classification() class to something short and easy to use.\n",
    "CL = gl.classification()\n",
    "\n",
    "print dir(CL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading samples\n",
    "* The `split_samples` module handles training samples. \n",
    "* One thing to keep in mind when using `classification` is that object variables do not need to be declared. Everything is inherited into our class (i.e., **cl**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method split_samples in module mpglue.classification.classification:\n",
      "\n",
      "split_samples(self, file_name, perc_samp=0.9, perc_samp_each=0, scale_data=False, class_subs=None, norm_struct=True, labs_type='int', recode_dict=None, classes2remove=None, sample_weight=None, ignore_feas=None, use_xy=False, stratified=False, spacing=1000.0, x_label='X', y_label='Y', response_label='response', clear_observations=None, min_observations=10) method of mpglue.classification.classification.classification instance\n",
      "    Split samples for training and testing.\n",
      "    \n",
      "    Args:\n",
      "        file_name (str or 2d array): Input text file or 2d array with samples and labels.\n",
      "        perc_samp (Optional[float]): Percent to sample from all samples. Default is .9. *This parameter\n",
      "            samples from the entire set of samples, regardless of which class they are in.\n",
      "        perc_samp_each (Optional[float]): Percent to sample from each class. Default is 0. *This parameter\n",
      "            overrides ``perc_samp`` and forces a percentage of samples from each class.\n",
      "        scale_data (Optional[bool]): Whether to scale (normalize) data. Default is False.\n",
      "        class_subs (Optional[dict]): Dictionary of class percentages or number to sample. Default is empty, or None.\n",
      "            Example:\n",
      "                Sample by percentage = {1:.9, 2:.9, 3:.5}\n",
      "                Sample by integer = {1:300, 2:300, 3:150}\n",
      "        norm_struct (Optional[bool]): Whether the structure of the data is normal. Default is True. \n",
      "            In MapPy's case, normal is (X,Y,Var1,Var2,Var3,Var4,...,VarN,Labels), \n",
      "            whereas the alternative (i.e., False) is (Labels,Var1,Var2,Var3,Var4,...,VarN)\n",
      "        labs_type (Optional[str]): Read class labels as integer ('int') or float ('float'). Default is 'int'.\n",
      "        recode_dict (Optional[dict]): Dictionary of classes to recode. Default is {}, or empty dictionary.\n",
      "        classes2remove (Optional[list]): List of classes to remove from samples. Default is [], or keep\n",
      "            all classes.\n",
      "        sample_weight (Optional[list or 1d array]): Sample weights. Default is None.\n",
      "        ignore_feas (Optional[list]): A list of feature (image layer) indexes to ignore. Default is [], or use all\n",
      "            features. *The features are sorted.\n",
      "        use_xy (Optional[bool]): Whether to use the x, y coordinates as predictive variables. Default is False.\n",
      "        stratified (Optional[bool]): Whether to stratify the samples. Default is False.\n",
      "        spacing (Optional[float]): The grid spacing (meters) to use for stratification (in ``stratified``).\n",
      "            Default is 1000.\n",
      "        x_label (str): The x coordinate label. Default is 'X'.\n",
      "        y_label (str): The y coordinate label. Default is 'Y'.\n",
      "        response_label (str): The response label. Default is 'response'.\n",
      "        clear_observations (Optional[array like]): Clear observations to filter samples by. Default is None.\n",
      "            *The array will be flattened if not 1d.\n",
      "        min_observations (Optional[int]): The minimum number of observations required in a time series.\n",
      "            *Uses `clear_observations`.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# let's look at the split_samples() help\n",
    "print help(CL.split_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "* We can see that `file_name` is the only required parameter. \n",
    "* After running, the **cl** instance contains new objects.\n",
    "* Let's load some samples and look at the class inheritance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XY', '__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_centroid_histogram', '_create_indices', '_default_parameters', '_get_feas', '_get_slope', '_index_samples', '_load_model', '_mask_background', '_num_rows_cols', '_plot_colors', '_predict', '_recode_labels', '_remove_classes', '_remove_min_observations', '_remove_outliers', '_scale_p_vars', '_set_model', '_set_parameters', '_stack_samples', '_stratify', '_train_model', '_transform4crf', '_update_class_counts', 'add_variable_names', 'all_samps', 'class_counts', 'classes', 'classes2remove', 'compare_features', 'compare_samples', 'construct_model', 'copy', 'extract_endmembers', 'file_name', 'get_abundance', 'get_class_subsample', 'get_test_train', 'grid_search', 'headers', 'label_idx', 'labels', 'labels_test', 'load4crf', 'min_observations', 'model_options', 'n_classes', 'n_feas', 'n_samps', 'optimize_parameters', 'p_vars', 'p_vars_test', 'p_vars_test_cols', 'p_vars_test_rows', 'perc_samp', 'perc_samp_each', 'predict', 'predict_array', 'rank_feas', 'recursive_elimination', 'remove_outliers', 'remove_values', 'sample_weight', 'scaled', 'semi_supervised', 'split_samples', 'stack_majority', 'sub_feas', 'test_accuracy', 'time_stamp', 'use_xy', 'vis_data', 'vis_decision', 'vis_dimensionality_reduction', 'vis_k_means', 'vis_parallel_coordinates', 'vis_series', 'weight_samples']\n"
     ]
    }
   ],
   "source": [
    "# Setup the samples\n",
    "samples = '../testing/data/08N_points_merged.txt'\n",
    "\n",
    "# Load the samples\n",
    "CL.split_samples(samples)\n",
    "\n",
    "print dir(CL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-330385.78125   113423.414062]\n",
      " [-330385.78125   113423.414062]\n",
      " [-330385.78125   113423.414062]\n",
      " ..., \n",
      " [-294261.75     -191333.578125]\n",
      " [-294261.75     -191333.578125]\n",
      " [-294261.75     -191333.578125]]\n"
     ]
    }
   ],
   "source": [
    "# the x, y coordinates\n",
    "print CL.XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "# the unique land cover classes\n",
    "print CL.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 ..., 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "# the class label vector\n",
    "print CL.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2104, 2: 1908, 3: 293, 4: 201, 5: 176, 6: 101}\n"
     ]
    }
   ],
   "source": [
    "# the number of land cover samples per class\n",
    "print CL.class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 141.          159.          152.         ...,   70.            1.86339998\n",
      "    29.        ]\n",
      " [ 120.          167.          143.         ...,   79.            2.12459993\n",
      "    28.        ]\n",
      " [ 127.          177.          143.         ...,  203.            0.           27.        ]\n",
      " ..., \n",
      " [ 115.          161.          148.         ...,   27.            0.58929998\n",
      "    23.        ]\n",
      " [ 129.          174.          144.         ...,  120.            2.4296\n",
      "    25.        ]\n",
      " [ 153.          167.          161.         ...,   68.            3.00460005\n",
      "    23.        ]]\n"
     ]
    }
   ],
   "source": [
    "# the image variables\n",
    "print CL.p_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `p_vars` is a 2-d array of (n_samples x n_variables)\n",
    "* the `labels` are a 1-d vector of n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image variables shape:  (4783, 41)\n",
      "Number of image variables:  41\n",
      "Number of class label samples:  4783\n",
      "Class counts:  {1: 2104, 2: 1908, 3: 293, 4: 201, 5: 176, 6: 101}\n"
     ]
    }
   ],
   "source": [
    "print 'Image variables shape: ', CL.p_vars.shape\n",
    "print 'Number of image variables: ', CL.n_feas\n",
    "print 'Number of class label samples: ', len(CL.labels)\n",
    "print 'Class counts: ', CL.class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have 4,783 land cover samples and 41 image variables. \n",
    "* Let's reload the data, but this time include the x, y coordinates as variables. \n",
    "* Also, we saw earlier that the samples are unbalanced, so let's take a more balanced sub-sample from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image variables shape:  (550, 43)\n",
      "Number of class label samples:  550\n",
      "Class counts:  {1: 100, 2: 100, 3: 100, 4: 100, 5: 100, 6: 50}\n"
     ]
    }
   ],
   "source": [
    "CL.split_samples(samples, \n",
    "                 use_xy=True, \n",
    "                 class_subs={0: 0, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100, 6: 50, 7: 100, 9: 100, 10: 100})\n",
    "\n",
    "print 'Image variables shape: ', cl.p_vars.shape\n",
    "print 'Number of class label samples: ', len(cl.labels)\n",
    "print 'Class counts: ', cl.class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The x, y coordinates are pre-pended onto p_vars.\n",
    "* You don't have to use all land cover samples. The `split_samples` function allows the aggregation of samples on-the-fly. In the example below we will merge classes 5--10 (say we have various types of forest cover classes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2340, 2: 2120, 3: 325, 4: 225, 5: 305}\n"
     ]
    }
   ],
   "source": [
    "CL.split_samples(samples, \n",
    "                 recode_dict={1:1, 2:2, 3:3, 4:4, 5:5, 6:5, 7:5, 8:5, 9:5, 10:5}, \n",
    "                 perc_samp=1.)\n",
    "\n",
    "print CL.class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You will notice more samples now that we have sampled 100% of the samples. \n",
    "* You might also have the situation where, after testing you find that a class either doesn't have sufficient samples or is not being estimated. The class can be removed. \n",
    "* Here we will remove classes 0 and 5--10 (our imaginary forest classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2340, 2: 2120, 3: 325, 4: 225}\n"
     ]
    }
   ],
   "source": [
    "CL.split_samples(samples, \n",
    "                 classes2remove=[0, 5, 6, 7, 8, 9, 10], \n",
    "                 perc_samp=1.)\n",
    "\n",
    "print CL.class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other options\n",
    "* Grid-based stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratifying ...\n"
     ]
    }
   ],
   "source": [
    "# Here we sample 70% of the training data to use for\n",
    "# model training, and the remaining 30% will be used\n",
    "# for model testing. Further, the samples are sampled\n",
    "# in a randonly stratified fashion. That is, a sample\n",
    "# is chosen from each 10km x 10km grid until 70% of the\n",
    "# samples is reached. The grids are generated on-the-fly.\n",
    "CL.split_samples(samples, \n",
    "                 perc_samp=.7, \n",
    "                 stratified=True, \n",
    "                 spacing=10000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the first two features in feature space\n",
    "CL.vis_data(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot three features\n",
    "# CL.vis_data(1, 2, fea_3=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
